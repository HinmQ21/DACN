# ===========================================
# Medical QA Multi-Agent System Configuration
# ===========================================

# API Keys (Required)
GOOGLE_API_KEY=your_google_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here

# Default LLM Configuration
GEMINI_MODEL=gemini-2.0-flash-exp
TEMPERATURE=0.3

# Agent-Specific Model Overrides (Optional)
# Leave empty to use default model
COORDINATOR_MODEL=
REASONING_MODEL=
VALIDATOR_MODEL=
ANSWER_GENERATOR_MODEL=
WEB_SEARCH_MODEL=

# Agent-Specific Temperature Overrides (Optional)
# Set to 0 to use default temperature
COORDINATOR_TEMPERATURE=0
REASONING_TEMPERATURE=0
VALIDATOR_TEMPERATURE=0
ANSWER_GENERATOR_TEMPERATURE=0
WEB_SEARCH_TEMPERATURE=0

# Benchmark Configuration
MAX_SAMPLES=100
BATCH_SIZE=5

# ===========================================
# Medprompt Configuration
# ===========================================

# Embedding Model for Few-shot Selection
# Recommended models:
# - pritamdeka/S-PubMedBert-MS-MARCO (medical domain, best for MedQA)
# - sentence-transformers/all-MiniLM-L6-v2 (fast, general purpose)
# - BAAI/bge-base-en-v1.5 (high quality general)
EMBEDDING_MODEL=pritamdeka/S-PubMedBert-MS-MARCO
EMBEDDING_CACHE_DIR=./cache/embeddings

# Dynamic Few-shot Selection
ENABLE_FEW_SHOT=true
FEW_SHOT_K=3
FEW_SHOT_MIN_SIMILARITY=0.3
KNN_INDEX_PATH=./data/knowledge_base/train_index.pkl

# Chain-of-Thought Reasoning
ENABLE_COT=true
COT_DETAILED=true

# Choice Shuffling Ensemble
ENABLE_ENSEMBLE=true
ENSEMBLE_VARIANTS=5
ENSEMBLE_CONFIDENCE_THRESHOLD=0.6

# Self-Consistency (for high-stakes questions)
ENABLE_SELF_CONSISTENCY=false
SELF_CONSISTENCY_SAMPLES=3
